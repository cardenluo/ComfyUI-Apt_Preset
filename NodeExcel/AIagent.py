



#region--------------------------------------------------------------------------


#endregion--------------------------------------------------------------------------



#region-----------GLM4.5V-------------------------------------

import os
import json
import base64
import random
from PIL import Image
import numpy as np
import io
import requests

try:
    from zhipuai import ZhipuAI
    ZHIPUAI_AVAILABLE = True
except ImportError:
    ZhipuAI = None
    ZHIPUAI_AVAILABLE = False

current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, "AiPromptPreset.json")

# åŠ è½½ JSON ä¸­çš„ PRESET_PROMPTS å­—å…¸ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
def load_preset_prompts():
    if not os.path.exists(json_path):
        # JSON æ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›é»˜è®¤å­—å…¸ï¼Œé¿å…æŠ¥é”™
        return {"None": ""}
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        # è¿”å› PRESET_PROMPTSï¼Œè‹¥ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å­—å…¸
        return data.get("PRESET_PROMPTS", {"None": ""})
    except Exception:
        # JSON æ ¼å¼é”™è¯¯æ—¶è¿”å›é»˜è®¤å­—å…¸
        return {"None": ""}

PRESET_PROMPTS = load_preset_prompts()

def _log_info(message):
    print(f"[GLM_Nodes] ä¿¡æ¯ï¼š{message}")

def _log_warning(message):
    print(f"[GLM_Nodes] è­¦å‘Šï¼š{message}")

def _log_error(message):
    print(f"[GLM_Nodes] é”™è¯¯ï¼š{message}")

def get_zhipuai_api_key():
    env_api_key = os.getenv("ZHIPUAI_API_KEY")
    if env_api_key:
        _log_info("ä½¿ç”¨ç¯å¢ƒå˜é‡ API Keyã€‚")
        return env_api_key
    _log_warning("æœªè®¾ç½®ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEYã€‚")
    return ""

# åŸæœ‰æ¨¡å‹åˆ—è¡¨ä¿ç•™
ZHIPU_MODELS = [
    "GLM-4.5-Flash",
    "glm-4v-flash",
    "XX----ä¸‹é¢çš„è¦å¼€é€šæ”¯ä»˜-----XX",
    "glm-4.5-air",
    "glm-4.5",
    "glm-4.5-x",
    "glm-4.5-airx",
    "glm-4.5-flash",
    "glm-4-plus",
    "glm-z1-air",
    "glm-4v-plus-0111",
    "glm-4.1v-thinking-flash"
]

class AI_GLM4:
    @classmethod
    def INPUT_TYPES(cls):
        # ä» JSON åŠ è½½çš„ PRESET_PROMPTS ä¸­è·å–é”®ï¼Œä½œä¸ºé¢„è®¾é€‰é¡¹
        prompt_keys = list(PRESET_PROMPTS.keys())
        default_selection = prompt_keys[0] if prompt_keys else ""

        return {
            "required": {
                "text_input": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "æ­¤å¤„æ˜¯è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬è¾“å…¥ï¼Œå›¾ç‰‡åˆ†æç”¨ç³»ç»Ÿæç¤ºè¯è¾“å…¥"
                }),
                "prompt_preset": (prompt_keys, {"default": default_selection}),
                "prompt_override": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": " è¾“å…¥ç³»ç»Ÿæç¤ºè¯ï¼Œç•™ç©ºåˆ™ç”¨é¢„è®¾"
                }),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 4096}),
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 0xffffffffffffffff,
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "å¯é€‰ï¼šæ™ºè°±AI API Key (ç•™ç©ºåˆ™å°è¯•ä»ç¯å¢ƒå˜é‡æˆ–config.jsonè¯»å–)"
                }),
                "model_name": (ZHIPU_MODELS, {
                    "default": "glm-4v-flash",
                    "placeholder": "è¯·è¾“å…¥æ¨¡å‹åç§°ï¼Œå¦‚ glm-4v-flash "
                }),
            },
            "optional": {
                "image_input": ("IMAGE", {"optional": True}),  # ç§»é™¤ tooltip å¤‡æ³¨
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("response",)
    FUNCTION = "execute"
    CATEGORY = "Apt_Preset/prompt"

    def execute(self, prompt_preset, prompt_override, api_key, model_name,
                max_tokens, seed, text_input, image_input=None):
        
        image_input_provided = image_input is not None
        
        if image_input_provided:
            return self._process_image(api_key, prompt_preset, prompt_override, model_name, seed,
                                     image_input, max_tokens)
        else:
            return self._process_text(text_input, api_key, prompt_preset, prompt_override, model_name,
                                    max_tokens, seed)

    def _process_text(self, text_input, api_key, prompt_preset, prompt_override, model_name,
                      max_tokens, seed):
        final_api_key = api_key.strip() or get_zhipuai_api_key()
        if not final_api_key:
            _log_error("API Key æœªæä¾›ã€‚")
            return ("API Key æœªæä¾›ã€‚",)

        _log_info("åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯ã€‚")

        try:
            client = ZhipuAI(api_key=final_api_key)
        except Exception as e:
            _log_error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return (f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}",)

        # ä» JSON åŠ è½½çš„ PRESET_PROMPTS ä¸­è·å–æç¤ºè¯ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
        final_system_prompt = ""
        if prompt_override and prompt_override.strip():
            final_system_prompt = prompt_override.strip()
            _log_info("ä½¿ç”¨ 'prompt_override'ã€‚")
        elif prompt_preset in PRESET_PROMPTS:
            final_system_prompt = PRESET_PROMPTS[prompt_preset]
            _log_info(f"ä½¿ç”¨é¢„è®¾æç¤ºè¯: '{prompt_preset}'ã€‚")
        else:
            # è‹¥é¢„è®¾ä¸å­˜åœ¨ï¼Œä½¿ç”¨å­—å…¸ç¬¬ä¸€ä¸ªå€¼ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
            final_system_prompt = next(iter(PRESET_PROMPTS.values()), "") if PRESET_PROMPTS else ""
            _log_warning("é¢„è®¾æç¤ºè¯æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯ã€‚")

        if not final_system_prompt:
            _log_error("ç³»ç»Ÿæç¤ºè¯ä¸èƒ½ä¸ºç©ºã€‚")
            return ("ç³»ç»Ÿæç¤ºè¯ä¸èƒ½ä¸ºç©ºã€‚",)

        if not isinstance(final_system_prompt, str):
            final_system_prompt = str(final_system_prompt)

        messages = [
            {"role": "system", "content": final_system_prompt},
            {"role": "user", "content": text_input}
        ]

        effective_seed = seed if seed != 0 else random.randint(0, 0xffffffffffffffff)
        _log_info(f"å†…éƒ¨ç§å­: {effective_seed}ã€‚")
        random.seed(effective_seed)

        _log_info(f"è°ƒç”¨ GLM-4 ({model_name})...")

        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.9,
                top_p=0.7,
                max_tokens=max_tokens,
            )
            response_text = response.choices[0].message.content
            _log_info("GLM-4 å“åº”æˆåŠŸã€‚")
            return (response_text,)
        except Exception as e:
            error_message = f"GLM-4 API è°ƒç”¨å¤±è´¥: {e}"
            return (error_message,)

    def _process_image(self, api_key, prompt_preset, prompt_override, model_name, seed,
                    image_input=None, max_tokens=1024):
        final_api_key = api_key.strip() or get_zhipuai_api_key()
        if not final_api_key:
            _log_error("API Key æœªæä¾›ã€‚")
            return ("API Key æœªæä¾›ã€‚",)
        _log_info("åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯ã€‚")

        try:
            client = ZhipuAI(api_key=final_api_key)
        except Exception as e:
            _log_error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return (f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}",)

        if image_input is None:
            _log_error("å¿…é¡»æä¾›æœ‰æ•ˆçš„IMAGEå¯¹è±¡ã€‚")
            return ("å¿…é¡»æä¾›æœ‰æ•ˆçš„IMAGEå¯¹è±¡ã€‚",)

        try:
            i = 255. * image_input.cpu().numpy()
            img_array = np.clip(i, 0, 255).astype(np.uint8)[0]
            img = Image.fromarray(img_array)
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            final_image_data = f"data:image/png;base64,{image_base64}"
            _log_info("IMAGEå¯¹è±¡æˆåŠŸè½¬æ¢ä¸ºBase64æ ¼å¼")
        except Exception as e:
            _log_error(f"å›¾ç‰‡æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
            return (f"å›¾ç‰‡æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}",)

        # ä» JSON åŠ è½½çš„ PRESET_PROMPTS ä¸­è·å–æç¤ºè¯ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
        final_prompt_text = ""
        if prompt_override and prompt_override.strip():
            final_prompt_text = prompt_override.strip()
            _log_info("ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯")
        elif prompt_preset in PRESET_PROMPTS:
            final_prompt_text = PRESET_PROMPTS[prompt_preset]
            _log_info(f"ä½¿ç”¨é¢„è®¾æç¤ºè¯: {prompt_preset}")
        else:
            final_prompt_text = next(iter(PRESET_PROMPTS.values()), "") if PRESET_PROMPTS else ""
            _log_warning("ä½¿ç”¨é»˜è®¤æç¤ºè¯")

        if not final_prompt_text:
            _log_error("æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            return ("æç¤ºè¯ä¸èƒ½ä¸ºç©º",)

        content_parts = [
            {"type": "text", "text": final_prompt_text},
            {"type": "image_url", "image_url": {"url": final_image_data}}
        ]

        effective_seed = seed if seed != 0 else random.randint(0, 0xffffffffffffffff)
        _log_info(f"ä½¿ç”¨å†…éƒ¨ç§å­: {effective_seed}")
        random.seed(effective_seed)

        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": content_parts}],
                temperature=0.9,
                top_p=0.7,
                max_tokens=max_tokens,
            )
            response_content = str(response.choices[0].message.content)
            _log_info("GLM-4Vå›¾ç‰‡è¯†åˆ«æˆåŠŸ")
            return (response_content,)
        except Exception as e:
            error_message = f"GLM-4V APIè°ƒç”¨å¤±è´¥: {str(e)}"
            _log_error(error_message)
            return (error_message,)



#endregion--------------------------------------------------------------------------




#region-------------ollama------------------

import base64
import json
import os
from io import BytesIO
import requests
from PIL import Image
import torch
import numpy as np
import subprocess
import os
import threading
from typing import Optional
import comfy.sd
import comfy.utils


current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, "AiPromptPreset.json")

def load_qwen_prompts():
    if not os.path.exists(json_path):
        return {"None": ""}
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        preset_data = data.get("QWEN_PROMPTS", {})
        if "None" not in preset_data:
            preset_data["None"] = ""
        return preset_data
    except Exception:
        return {"None": ""}

QWEN_PROMPTS = load_qwen_prompts()
OLLMAMA_MODEL_NAME = ["qwen3-vl:latest", "llama3:8b"]

def resize_to_limit(img, max_pixels=262144):
    width, height = img.size
    total_pixels = width * height
    if total_pixels <= max_pixels:
        return img
    scale = (max_pixels / total_pixels) ** 0.5
    new_width = int(width * scale)
    new_height = int(height * scale)
    return img.resize((new_width, new_height), Image.LANCZOS)

class AI_Ollama_image:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_name": (OLLMAMA_MODEL_NAME, {"default": "qwen3-vl:latest"}),
                "preset": (list(QWEN_PROMPTS.keys()), {"default": "None"}),
                "analysis_prompt": ("STRING", {"multiline": True, "default": ""}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 2048, "min": 1, "max": 8192}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 999999999, "step": 1}),
            },
            "optional": {
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "enable_ocr": ("BOOLEAN", {"default": False}),
            },
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("analysis_result", "system_prompt")
    FUNCTION = "run_image_analysis"
    CATEGORY = "Apt_Preset/prompt"

    DESCRIPTION = """
    CMDè¿è¡Œå‘½ä»¤:  ollama run qwen3-vl:latest
    """

    def run_image_analysis(
        self,
        model_name,
        preset,
        analysis_prompt,
        temperature,
        max_tokens,
        seed=0,
        image_1=None,
        image_2=None,
        image_3=None,
        enable_ocr=False
    ):
        cleaned_analysis_prompt = analysis_prompt.strip()
        if cleaned_analysis_prompt:
            final_prompt = cleaned_analysis_prompt
        else:
            preset_prompt = QWEN_PROMPTS.get(preset, "").strip()
            final_prompt = preset_prompt if preset_prompt else "è¯·åŸºäºè¾“å…¥å›¾ç‰‡ï¼Œè¯¦ç»†æè¿°å†…å®¹ã€åˆ†æç‰©ä½“/åœºæ™¯/ç»†èŠ‚ï¼Œè‹¥æœ‰å¤šå¼ å›¾éœ€å¯¹æ¯”å¼‚åŒ"

        img_base64_list = []
        img_inputs = [image_1, image_2, image_3]
        
        for idx, img_tensor in enumerate(img_inputs, 1):
            if img_tensor is not None:
                try:
                    if len(img_tensor.shape) == 4:
                        img_tensor = img_tensor.squeeze(0)
                    if img_tensor.dtype == torch.float32:
                        img_tensor = (img_tensor * 255).byte()
                    
                    img_np = img_tensor.cpu().numpy().astype(np.uint8)
                    if img_np.shape[-1] == 4:
                        img_np = img_np[..., :3]
                    img_pil = Image.fromarray(img_np)

                    img_pil = resize_to_limit(img_pil)

                    img_buffer = BytesIO()
                    img_pil.save(img_buffer, format="JPEG", quality=95, optimize=True)
                    img_buffer.seek(0)
                    
                    img_base64 = base64.b64encode(img_buffer.getvalue()).decode("utf-8").strip()
                    img_base64_list.append(img_base64)
                except Exception as e:
                    return (f"å›¾ç‰‡{idx}å¤„ç†/ç¼–ç é”™è¯¯ï¼š{str(e)}", final_prompt)

        if not img_base64_list:
            return ("é”™è¯¯ï¼šæœªè¾“å…¥ä»»ä½•å›¾ç‰‡ï¼Œè¯·è‡³å°‘é€‰æ‹©1å¼ å›¾ç‰‡ä¸Šä¼ ", final_prompt)

        if enable_ocr:
            img_count = len(img_base64_list)
            ocr_msg = f"\n\nç‰¹åˆ«æŒ‡ä»¤ï¼šè¯·æå–{img_count}å¼ å›¾ç‰‡ä¸­æ‰€æœ‰å¯è§æ–‡æœ¬å†…å®¹ï¼ŒæŒ‰å›¾ç‰‡åºå·ï¼ˆ1-{img_count}ï¼‰åˆ†ç±»ï¼Œä»¥åˆ—è¡¨å½¢å¼æ•´ç†æ–‡æœ¬å†…å®¹åŠæ–‡å­—ä½ç½®ä¿¡æ¯"
            final_prompt += ocr_msg

        ollama_host = "http://localhost:11434"

        try:
            data = {
                "model": model_name,
                "prompt": final_prompt,
                "images": img_base64_list,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": True,
                "options": {
                    "num_ctx": max_tokens,
                    "num_thread": 4
                }
            }

            if seed != 0:
                data["seed"] = seed

            url = f"{ollama_host}/api/generate"
            headers = {"Content-Type": "application/json", "Accept": "application/json"}
            response = requests.post(
                url,
                headers=headers,
                data=json.dumps(data),
                stream=True,
                timeout=300
            )
            response.raise_for_status()

            analysis_result = ""
            for line in response.iter_lines():
                if line:
                    try:
                        line_data = json.loads(line.decode("utf-8"))
                        if "response" in line_data:
                            analysis_result += line_data["response"]
                        if line_data.get("error"):
                            return (f"æ¨¡å‹é”™è¯¯ï¼š{line_data['error']}", final_prompt)
                        if line_data.get("done", False):
                            break
                    except json.JSONDecodeError:
                        continue

            analysis_result = analysis_result.strip()
            if not analysis_result:
                return ("é”™è¯¯ï¼šæ¨¡å‹æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒè§†è§‰åˆ†æ", final_prompt)

            return (analysis_result, final_prompt)

        except requests.exceptions.ConnectionError:
            error_msg = "è¿æ¥é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·æ£€æŸ¥Ollamaæ˜¯å¦å·²å¯åŠ¨ã€æœåŠ¡åœ°å€æ­£ç¡®ã€ç«¯å£11434æœªè¢«å ç”¨"
            return (error_msg, final_prompt)
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                error_msg = f"æ¨¡å‹æœªæ‰¾åˆ°ï¼šè¯·å…ˆæ‰§è¡Œ `ollama pull {model_name}` ä¸‹è½½æ¨¡å‹ï¼ˆç¡®ä¿æ¨¡å‹æ”¯æŒè§†è§‰åˆ†æï¼Œå¦‚qwen3-vlã€llavaç­‰ï¼‰"
            elif e.response.status_code == 500:
                error_msg = f"OllamaæœåŠ¡å†…éƒ¨é”™è¯¯ï¼š1. è¯·æ›´æ–°Ollamaåˆ°æœ€æ–°ç‰ˆæœ¬ï¼ˆâ‰¥0.12.7ï¼‰ï¼›2. é‡æ–°æ‹‰å–æ¨¡å‹ `ollama pull {model_name}`ï¼›3. æ£€æŸ¥å›¾ç‰‡æ˜¯å¦æŸå"
            else:
                error_msg = f"HTTPé”™è¯¯ï¼š{str(e)}"
            return (error_msg, final_prompt)
        except requests.exceptions.Timeout:
            return ("é”™è¯¯ï¼šè¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å¢å¤§è¶…æ—¶æ—¶é—´", final_prompt)
        except Exception as e:
            error_msg = f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}"
            return (error_msg, final_prompt)
        

class AI_Ollama_text:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_name": ("STRING", {"default": "llama3:8b"}),
                "preset": (list(PRESET_PROMPTS.keys()), {"default": "None"}),
                "prompt": ("STRING", {"multiline": True, "default": ""}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.1}),
                "max_tokens": ("INT", {"default": 512, "min": 1, "max": 4096}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 999999999, "step": 1}),
            },
            "optional": {},
        }

    RETURN_TYPES = ("STRING",)
    FUNCTION = "run"
    RETURN_NAMES = ("pos", )
    CATEGORY = "Apt_Preset/prompt"

    def run(self, model_name, preset, prompt, temperature, max_tokens, seed=0):
        system_prompt = QWEN_PROMPTS.get(preset, "") if preset != "None" else ""
        
        ollama_host="http://localhost:11434"
        try:
            url = f"{ollama_host}/api/generate"
            headers = {"Content-Type": "application/json"}
            data = {
                "model": model_name,
                "prompt": prompt,
                "system": system_prompt,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            if seed != 0:
                data["seed"] = seed

            response = requests.post(url, headers=headers, data=json.dumps(data))
            response.raise_for_status()

            result = ""
            for line in response.iter_lines():
                if line:
                    line_data = json.loads(line.decode('utf-8'))
                    if 'response' in line_data:
                        result += line_data['response']
                    if line_data.get('done', False):
                        break

            return (result,)
        except Exception as e:
            print(f"Ollama APIè°ƒç”¨é”™è¯¯: {str(e)}")
            return (f"é”™è¯¯: {str(e)}",)




class Ai_Ollama_RunModel:
    def __init__(self):
        self.process: Optional[subprocess.Popen] = None
        self.is_running = False

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_name": ("STRING", {
                    "default": "qwen3-vl:latest",
                    "multiline": False
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("status",)
    FUNCTION = "run_ollama_model"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def run_ollama_model(self, model_name: str):

        if not model_name.strip():
            return ("é”™è¯¯ï¼šæ¨¡å‹åç§°ä¸èƒ½ä¸ºç©ºï¼",)

        cmd = ["ollama", "run", model_name.strip()]
        
        stdout = subprocess.PIPE
        stderr = subprocess.STDOUT

        try:
            self.process = subprocess.Popen(
                cmd,
                stdout=stdout,
                stderr=stderr,
                text=True,
                bufsize=1,
                universal_newlines=True,
                creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
            )

            self.is_running = True
            pid = self.process.pid
            result = f"æˆåŠŸå¯åŠ¨è¿›ç¨‹ï¼å‘½ä»¤ï¼š{' '.join(cmd)} | è¿›ç¨‹IDï¼š{pid}\n" \
                     f"æç¤ºï¼šè¿›ç¨‹åœ¨åå°è¿è¡Œï¼Œæ—¥å¿—å¯åœ¨ ComfyUI æ§åˆ¶å°æŸ¥çœ‹ | åœæ­¢è¿›ç¨‹éœ€æ‰‹åŠ¨ç»“æŸ PID:{pid}"

            threading.Thread(
                target=self._print_output,
                args=(self.process,),
                daemon=True
            ).start()

            return (result,)

        except FileNotFoundError:
            error_msg = (
                "é”™è¯¯ï¼šæœªæ‰¾åˆ° ollama å‘½ä»¤ï¼\n"
                "è¯·ç¡®ä¿ï¼š1. å·²å®‰è£… Ollamaï¼ˆhttps://ollama.com/downloadï¼‰\n"
                "       2. Ollama å·²æ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡"
            )
            return (error_msg,)
        except Exception as e:
            error_msg = f"é”™è¯¯ï¼šæ‰§è¡Œå‘½ä»¤å¤±è´¥ï¼\nå¼‚å¸¸ä¿¡æ¯ï¼š{str(e)}\n"
            if "no such model" in str(e).lower():
                error_msg += "æç¤ºï¼šæ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œ `ollama pull æ¨¡å‹åç§°` ä¸‹è½½"
            return (error_msg,)

    def _print_output(self, process: subprocess.Popen):
        while self.is_running and process.poll() is None:
            line = process.stdout.readline()
            if line:
                print(f"[Ollama è¾“å‡º] {line.strip()}")
        for line in process.stdout:
            print(f"[Ollama è¾“å‡º] {line.strip()}")
        self.is_running = False





#endregion--------------------------------------------------------------------------



#region-----------qwen-image edit---

import requests
from io import BytesIO
import os
import io
import base64
import json
import folder_paths
import numpy as np
from PIL import Image


try:
    import dashscope
    REMOVER_AVAILABLE = True  
except ImportError:
    dashscope = None
    REMOVER_AVAILABLE = False  


current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, "AiPromptPreset.json")

def load_qwen_prompts():
    if not os.path.exists(json_path):
        return {"None": ""}
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("QWEN_PROMPTS", {"None": ""})
    except Exception:
        return {"None": ""}

QWEN_PROMPTS = load_qwen_prompts()

custom_nodes_paths = folder_paths.get_folder_paths("custom_nodes")
comfy_root = os.path.dirname(custom_nodes_paths[0]) if custom_nodes_paths else os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))

key_path = os.path.join(comfy_root, "custom_nodes", "ComfyUI-Apt_Preset", "NodeExcel", "ApiKey_AI_Qwen.txt")

def get_aliyun_api_key():
    env_api_key = os.getenv("aliyun_API_KEY")
    if env_api_key and env_api_key.strip():
        return env_api_key.strip()
    if os.path.exists(key_path):
        try:
            with open(key_path, "r", encoding="utf-8") as f:
                api_key = f.read().strip()
                if api_key:
                    return api_key
        except:
            pass
    return ""

def encode_image(pil_image, save_tokens=True):
    buffered = io.BytesIO()
    if save_tokens:
        image = resize_to_limit(pil_image)
        image.save(buffered, format="JPEG", optimize=True, quality=75)
    else:
        pil_image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode("utf-8")

def resize_to_limit(img, max_pixels=262144):
    width, height = img.size
    total_pixels = width * height
    if total_pixels <= max_pixels:
        return img
    scale = (max_pixels / total_pixels) ** 0.5
    return img.resize((int(width * scale), int(height * scale)), Image.LANCZOS)

def tensor2pil(image):
    batch_count = image.size(0) if len(image.shape) > 3 else 1
    if batch_count > 1:
        return [tensor2pil(image[i])[0] for i in range(batch_count)]
    return [Image.fromarray(np.clip(255.0 * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))]

def analyze_images(images, model, api_key, final_prompt, max_tokens, seed=None, max_retries=3):
    if not api_key:
        raise ValueError("APIå¯†é’¥æœªé…ç½®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®ï¼š\n1. è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ aliyun_API_KEY\n2. åœ¨custom_nodes/ComfyUI-Apt_Preset/NodeExcelç›®å½•ä¸‹åˆ›å»ºApiKey_AI_Qwen.txtå¹¶å†™å…¥å¯†é’¥")
    
    img_count = len(images)
    user_text = f"è¯·æŒ‰è¦æ±‚åˆ†æä»¥ä¸‹{img_count}å¼ å›¾ç‰‡ï¼ˆæŒ‰è¾“å…¥é¡ºåºï¼‰ï¼š{final_prompt}"
    if seed is not None and seed != 0:
        user_text += f"\nã€å›ºå®šç§å­ï¼š{seed}ã€‘"
    
    user_content = []
    for img in images:
        user_content.append({"image": f"data:image/png;base64,{encode_image(img)}"})
    user_content.append({"text": user_text})
    
    messages = [{"role": "user", "content": user_content}]
    
    for retry in range(max_retries):
        try:
            call_params = {
                "api_key": api_key, 
                "model": model, 
                "messages": messages, 
                "result_format": "message",
                "max_tokens": max_tokens
            }
            if seed is not None and seed != 0:
                call_params["seed"] = seed
            
            response = dashscope.MultiModalConversation.call(**call_params)
            if response.status_code == 200:
                return response.output.choices[0].message.content[0]["text"].strip()
            else:
                raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.message}")
        except Exception as e:
            if "seed" in str(e).lower() and retry < max_retries - 1:
                call_params.pop("seed", None)
                response = dashscope.MultiModalConversation.call(**call_params)
                if response.status_code == 200:
                    return response.output.choices[0].message.content[0]["text"].strip()
            if retry == max_retries - 1:
                raise Exception(f"å¤šæ¬¡å°è¯•åå¤±è´¥: {str(e)}")
            

class AI_Qwen:
    def __init__(self):
        self.api_key = get_aliyun_api_key()

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (["qwen-vl-max", "qwen-vl-max-latest"], {"default": "qwen-vl-max-latest"}),
                "preset": (list(QWEN_PROMPTS.keys()), {"default": "None"}),
                "text": ("STRING", {"default": "", "multiline": True}),
                "max_tokens": ("INT", {
                    "default": 1024,
                    "min": 10,
                    "max": 8192,
                    "step": 10,
                }),
            },
            "optional": {

                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "seed": ("INT", {"default": 0, "min": 0, "max": 999999999, "step": 1}),
                "api_key_input": ("STRING", {"default": "", "multiline": False, }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("result", "system_prompt")
    FUNCTION = "analyze"
    CATEGORY = "Apt_Preset/prompt"

    def analyze(self, model, preset, text, max_tokens, api_key_input="", image_1=None, image_2=None, image_3=None, seed=0):
        # è·å–presetå¯¹åº”çš„æ–‡æœ¬å†…å®¹ï¼ˆé”®åæ˜ å°„åˆ°å€¼ï¼‰
        preset_text = QWEN_PROMPTS.get(preset, "") if preset != "None" else ""
        text_content = text.strip()
        
        # ç¡®å®šæœ€ç»ˆæç¤ºè¯
        if text_content:
            final_prompt = text_content
        else:
            final_prompt = preset_text if preset_text else "ç”Ÿæˆè¾“å…¥å›¾ç‰‡çš„è¯¦ç»†ä¸­æ–‡æè¿°"

        input_images = []
        if image_1 is not None:
            pil_img = tensor2pil(image_1)[0]
            if pil_img:
                input_images.append(pil_img)
        if image_2 is not None:
            pil_img = tensor2pil(image_2)[0]
            if pil_img:
                input_images.append(pil_img)
        if image_3 is not None:
            pil_img = tensor2pil(image_3)[0]
            if pil_img:
                input_images.append(pil_img)
        
        if not input_images:
            return ("é”™è¯¯ï¼šè¯·è‡³å°‘è¾“å…¥1å¼ æœ‰æ•ˆå›¾ç‰‡", preset_text)
        
        # ä½¿ç”¨ä¼ å…¥çš„API keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ–¹å¼è·å–
        api_key = api_key_input.strip() if api_key_input.strip() else self.api_key
        if not api_key:
            return ("APIå¯†é’¥æœªé…ç½®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®ï¼š\n1. åœ¨èŠ‚ç‚¹è¾“å…¥ä¸­ç›´æ¥å¡«å†™APIå¯†é’¥\n2. è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ aliyun_API_KEY\n3. æˆ–åœ¨custom_nodes/ComfyUI-Apt_Preset/NodeExcelç›®å½•ä¸‹åˆ›å»ºApiKey_AI_Qwen.txtå¹¶å†™å…¥å¯†é’¥", preset_text)
        
        try:
            result = analyze_images(
                input_images, 
                model, 
                api_key, 
                final_prompt, 
                max_tokens,
                seed if seed != 0 else None
            )
            return (result, preset_text)
        except Exception as e:
            return (f"åˆ†æå¤±è´¥: {str(e)}", preset_text)

#endregion--------------------------------------------------------------------------



#region-----------qwen-prompt-----------------

try:
    import dashscope
    from dashscope import Conversation
    REMOVER_AVAILABLE = True
except ImportError:
    dashscope = None
    Conversation = None
    REMOVER_AVAILABLE = False

def analyze_text(model, api_key, final_prompt, max_tokens, seed=None, max_retries=3):
    if not api_key:
        raise ValueError("APIå¯†é’¥æœªé…ç½®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®ï¼š\n1. è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ aliyun_API_KEY\n2. åœ¨custom_nodes/ComfyUI-Apt_Preset/NodeExcelç›®å½•ä¸‹åˆ›å»ºApiKey_AI_Qwen.txtå¹¶å†™å…¥å¯†é’¥")
    
    if not Conversation:
        raise ImportError("dashscope.Conversation å¯¼å…¥å¤±è´¥ï¼Œè¯·ç¡®ä¿dashscopeåº“ç‰ˆæœ¬æ­£ç¡®")
    
    user_text = final_prompt
    if seed is not None and seed != 0:
        user_text += f"\nã€å›ºå®šç§å­ï¼š{seed}ã€‘"
    
    messages = [{"role": "user", "content": user_text}]
    
    for retry in range(max_retries):
        try:
            conv = Conversation()
            call_params = {
                "api_key": api_key, 
                "model": model, 
                "messages": messages, 
                "result_format": "message",
                "max_tokens": max_tokens,
                "temperature": 0.7,
                "top_p": 0.8
            }
            if seed is not None and seed != 0:
                call_params["seed"] = seed
            
            response = conv.call(**call_params)
            if response.status_code == 200:
                return response.output.choices[0].message.content.strip()
            else:
                raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.message} (çŠ¶æ€ç ï¼š{response.status_code})")
        except Exception as e:
            if "seed" in str(e).lower() and retry < max_retries - 1:
                call_params.pop("seed", None)
                conv_retry = Conversation()
                response = conv_retry.call(**call_params)
                if response.status_code == 200:
                    return response.output.choices[0].message.content.strip()
            if retry == max_retries - 1:
                raise Exception(f"å¤šæ¬¡å°è¯•åå¤±è´¥: {str(e)}")

# ä¿®å¤ç³»ç»Ÿæç¤ºè¯åŠ è½½é€»è¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, "AiPromptPreset.json")

def load_PRESET_PROMPTS():
    if not os.path.exists(json_path):
        return {"None": ""}
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("PRESET_PROMPTS", {"None": ""})
    except Exception:
        return {"None": ""}

PRESET_PROMPTS = load_PRESET_PROMPTS()

class AI_Qwen_text:
    def __init__(self):
        self.api_key = get_aliyun_api_key()

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "llm_model": (["qwen3-coder-plus", "qwen3-coder-plus-2025-09-23", "qwen3-coder-flash", 
                              "qwen3-coder-480b-a35b-instruct", "qwen3-coder-30b-a3b-instruct"], {
                    "default": "qwen3-coder-plus",
                }),
                "preset": (list(PRESET_PROMPTS.keys()), {"default": "None"}),
                "text": ("STRING", {"default": "", "multiline": True}),
                "max_tokens": ("INT", {
                    "default": 1024,
                    "min": 10,
                    "max": 8192,
                    "step": 10,
                }),
            },
            "optional": {
                "seed": ("INT", {"default": 0, "min": 0, "max": 999999999, "step": 1}),
                "api_key_input": ("STRING", {"default": "", "multiline": False, }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("result", "system_prompt")
    FUNCTION = "analyze"
    CATEGORY = "Apt_Preset/prompt"

    def analyze(self, llm_model, preset, text, max_tokens, api_key_input="", seed=0):
        preset_text = PRESET_PROMPTS.get(preset, "") if preset != "None" else ""
        text_content = text.strip()
        
        if text_content and preset_text:
            final_prompt = f"{preset_text}\n\n{text_content}"
        elif text_content:
            final_prompt = text_content
        else:
            final_prompt = preset_text if preset_text else "è¯·æ ¹æ®éœ€æ±‚å®Œæˆç›¸å…³ä»£ç æˆ–æ–‡æœ¬ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€ä»£ç è§£é‡Šã€ç¼–ç¨‹é—®é¢˜è§£ç­”ç­‰ï¼‰"

        if not final_prompt.strip():
            return ("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬æˆ–é€‰æ‹©åˆé€‚çš„é¢„è®¾", preset_text)
        
        if not REMOVER_AVAILABLE or not Conversation:
            return ("é”™è¯¯ï¼šdashscopeåº“å¯¼å…¥å¤±è´¥ï¼Œè¯·å®‰è£…æœ€æ–°ç‰ˆæœ¬dashscopeï¼ˆpip install -U dashscopeï¼‰", preset_text)
        
        api_key = api_key_input.strip() if api_key_input.strip() else self.api_key
        if not api_key:
            return ("APIå¯†é’¥æœªé…ç½®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®ï¼š\n1. åœ¨èŠ‚ç‚¹è¾“å…¥ä¸­ç›´æ¥å¡«å†™APIå¯†é’¥\n2. è®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ aliyun_API_KEY\n3. æˆ–åœ¨custom_nodes/ComfyUI-Apt_Preset/NodeExcelç›®å½•ä¸‹åˆ›å»ºApiKey_AI_Qwen.txtå¹¶å†™å…¥å¯†é’¥", preset_text)
        
        try:
            result = analyze_text(
                llm_model, 
                api_key, 
                final_prompt, 
                max_tokens,
                seed if seed != 0 else None
            )
            return (result, preset_text)
        except Exception as e:
            return (f"å¤„ç†å¤±è´¥: {str(e)}", preset_text)

#endregion--------------------------------------------------------------------------









#region-----------------ä¿å­˜æç¤ºè¯------------

import os
import json
import folder_paths

current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, "AiPromptPreset.json")

# ç¡®ä¿JSONæ–‡ä»¶å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºé»˜è®¤æ–‡ä»¶
def init_json_file():
    if not os.path.exists(json_path):
        default_data = {
            "PRESET_PROMPTS": {"None": ""},
            "QWEN_PROMPTS": {"None": ""}
        }
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(default_data, f, ensure_ascii=False, indent=4)

init_json_file()

def load_prompt_dicts():
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)

def save_prompt_dicts(data):
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)



Analyze_text_Preset = "PRESET_PROMPTS"
Analyze_image_Preset = "QWEN_PROMPTS"

class AI_PresetSave:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "target_dict": ([Analyze_text_Preset, Analyze_image_Preset], {"default": Analyze_image_Preset}),
                "prompt_title": ("STRING", {"default": "", "placeholder": "è¾“å…¥æç¤ºè¯æ ‡é¢˜ï¼ˆä½œä¸ºå­—å…¸çš„é”®ï¼‰"}),
                "prompt_content": ("STRING", {"default": "", "multiline": True, "placeholder": "è¾“å…¥æç¤ºè¯å†…å®¹ï¼ˆä½œä¸ºå­—å…¸çš„å€¼ï¼‰"}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("result",)
    FUNCTION = "append_prompt"
    CATEGORY = "Apt_Preset/prompt"
 

    def append_prompt(self, target_dict, prompt_title, prompt_content):
        prompt_title = prompt_title.strip()
        prompt_content = prompt_content.strip()
        if not prompt_title:
            return ("é”™è¯¯ï¼šæç¤ºè¯æ ‡é¢˜ä¸èƒ½ä¸ºç©º",)
        if not prompt_content:
            return ("é”™è¯¯ï¼šæç¤ºè¯å†…å®¹ä¸èƒ½ä¸ºç©º",)
        try:
            data = load_prompt_dicts()
        except Exception as e:
            return (f"é”™è¯¯ï¼šåŠ è½½JSONå¤±è´¥ - {str(e)}",)
        if target_dict not in data:
            return (f"é”™è¯¯ï¼šJSONä¸­ä¸å­˜åœ¨{target_dict}å­—å…¸",)
        if prompt_title in data[target_dict]:
            return (f"é”™è¯¯ï¼š{target_dict}ä¸­å·²å­˜åœ¨æ ‡é¢˜ã€Œ{prompt_title}ã€",)
        data[target_dict][prompt_title] = prompt_content
        try:
            save_prompt_dicts(data)
        except Exception as e:
            return (f"é”™è¯¯ï¼šä¿å­˜JSONå¤±è´¥ - {str(e)}",)
        return (f"æˆåŠŸï¼šå‘{target_dict}æ°¸ä¹…è¿½åŠ æç¤ºè¯\næ ‡é¢˜ï¼š{prompt_title}\nå†…å®¹ï¼š{prompt_content[:50]}...",)
    

#endregion--------------------------------------------------------------------------









#endregion--------------------------------------------------------------------------





















