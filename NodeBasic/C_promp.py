import os
import torch
import re
from comfy.sd1_clip import gen_empty_tokens
import random
from pathlib import Path
import folder_paths
import comfy
import os, re, io, base64, csv, shutil, requests, chardet, pathlib
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple


from PIL import Image as PILImage
from io import BytesIO



from ..main_unit import *


#------------------------------------------------------------
# å®‰å…¨å¯¼å…¥æ£€æŸ¥ -- å°†å¯¼å…¥è¯­å¥ä¿®æ”¹ä¸ºä»¥ä¸‹å½¢å¼
try:
    from transformers import T5Tokenizer, T5ForConditionalGeneration
except ImportError:
    T5Tokenizer = None
    T5ForConditionalGeneration = None
    print("Warning: transformers not installed, SuperPrompter node will not be available")

try:
    import openpyxl
except ImportError:
    openpyxl = None
    print("Warning: openpyxl not installed, Excel-related nodes will not be available")

try:
    from openpyxl.drawing.image import Image as OpenpyxlImage
except ImportError:
    OpenpyxlImage = None
    print("Warning: openpyxl.drawing.image not available")

try:
    from openpyxl.utils import get_column_letter
except ImportError:
    get_column_letter = None
    print("Warning: openpyxl.utils.get_column_letter not available")

try:
    from openpyxl import Workbook
except ImportError:
    Workbook = None
    print("Warning: openpyxl.Workbook not available")

#------------------------------------------------------------


#region----------------------------------------------------------------------#

class text_SuperPrompter:
    def __init__(self):
        self.modelDir = os.path.expanduser("~") + "/.models"
        self.tokenizer = None
        self.model = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"default": "Enter prompt here"}),
                "max_new_tokens": ("INT", {"default": 77, "min": 1, "max": 2048}),
                "repetition_penalty": ("FLOAT", {"default": 1.2, "min": 0.0, "max": 2.0, "step": 0.1}),
                "remove_incomplete_sentences": ("BOOLEAN", {"default": True}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("generated_text",)
    FUNCTION = "generate_text"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def remove_incomplete_sentence(self, paragraph):
        return re.sub(r'((?:\[^.!?\](?!\[.!?\]))\*+\[^.!?\\s\]\[^.!?\]\*$)', '', paragraph.rstrip())

    def download_models(self):
        model_name = "roborovski/superprompt-v1"
        self.tokenizer = T5Tokenizer.from_pretrained(model_name)
        self.model = T5ForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.float16)
        os.makedirs(self.modelDir, exist_ok=True)
        self.tokenizer.save_pretrained(self.modelDir)
        self.model.save_pretrained(self.modelDir)
        print("Downloaded SuperPrompt-v1 model files to", self.modelDir)

    def load_models(self):
        if not all(os.path.exists(self.modelDir) for file in self.modelDir):
            self.download_models()
        else:
            print("Model files found. Skipping download.")

        self.tokenizer = T5Tokenizer.from_pretrained(self.modelDir)
        self.model = T5ForConditionalGeneration.from_pretrained(self.modelDir, torch_dtype=torch.float16)
        print("SuperPrompt-v1 model loaded successfully.")

    def generate_text(self, prompt, max_new_tokens, repetition_penalty, remove_incomplete_sentences):
        if self.tokenizer is None or self.model is None:
            self.load_models()

        seed = 1
        torch.manual_seed(seed)
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        systemprompt = "Expand the following prompt to add more detail:"
        input_ids = self.tokenizer(systemprompt + prompt, return_tensors="pt").input_ids.to(device)
        if torch.cuda.is_available():
            self.model.to('cuda')

        outputs = self.model.generate(input_ids, max_new_tokens=max_new_tokens, repetition_penalty=repetition_penalty,
                                      do_sample=True)

        dirty_text = self.tokenizer.decode(outputs[0])
        text = dirty_text.replace("<pad>", "").replace("</s>", "").strip()
        
        if remove_incomplete_sentences:
            text = self.remove_incomplete_sentence(text)
        
        return (text,)



class text_mul_replace:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text": ("STRING", {"multiline": True}),
                "target": ("STRING", {
                    "multiline": False,
                    "default": "man, dog "
                }),
                "replace": ("STRING", {
                    "multiline": False,
                    "default": "dog, man, "
                })
            }
        }
        
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "replace"
    CATEGORY = "Apt_Preset/prompt"

    def replace(self, text, target, replace):
        import re  # æ³¨æ„è¡¥å……reçš„å¯¼å…¥ï¼ˆåŸä»£ç å¯èƒ½é—æ¼ï¼‰
        def split_with_quotes(s):
            pattern = r'"([^"]*)"|\s*([^,]+)'
            matches = re.finditer(pattern, s)
            return [match.group(1) or match.group(2).strip() for match in matches if match.group(1) or match.group(2).strip()]
        
        targets = split_with_quotes(target)
        exchanges = split_with_quotes(replace)
    
        word_map = {}
        for target, exchange in zip(targets, exchanges):
            target_clean = target.strip('"').strip()  # å»æ‰lower()ï¼Œé¿å…å¤§å°å†™è½¬æ¢å½±å“ï¼ˆå¦‚åŸç›®æ ‡å«å¤§å†™æ—¶ï¼‰
            exchange_clean = exchange.strip('"').strip()
            word_map[target_clean] = exchange_clean
    
        sorted_targets = sorted(word_map.keys(), key=len, reverse=True)
        
        result = text
        for target in sorted_targets:
            pattern = re.escape(target)
            result = re.sub(pattern, word_map[target], result)
        
        
        return (result,)

    @classmethod
    def IS_CHANGED(cls, text, target, replace):
        return (text, target, replace)



class text_mul_remove:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text": ("STRING", {"multiline": True}),
                "words_to_remove": ("STRING", {
                    "multiline": False,
                    "default": "man, woman, world"
                })
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "clean_prompt"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def clean_prompt(self, text, words_to_remove):
        # æ‹†åˆ†å¾…ç§»é™¤çš„è¯ï¼ˆå¤„ç†å¯èƒ½çš„ç©ºæ ¼å’Œç©ºå­—ç¬¦ä¸²ï¼‰
        remove_words = [word.strip() for word in words_to_remove.split(',') if word.strip()]
        if not remove_words:
            return (text,)
    
        remove_words_sorted = sorted(remove_words, key=lambda x: len(x), reverse=True)
        
        pattern = '|'.join(re.escape(word) for word in remove_words_sorted)
        cleaned_text = re.sub(pattern, '', text)

        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()    
        return (cleaned_text,)

    @classmethod
    def IS_CHANGED(cls, text, words_to_remove):
        return (text, words_to_remove)


class text_free_wildcards:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True}),
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 0xFFFFFFFF
                }),
                "wildcard_symbol": ("STRING", {"default": "@@"}),
                "recursive_depth": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 10,
                    "step": 1
                })
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "process_wildcards"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def process_wildcards(self, prompt, seed, wildcard_symbol, recursive_depth):
        random.seed(seed)
        wildcards_folder = Path(__file__).parent.parent  / "wildcards"
        
        logger.debug(f"Wildcards folder: {wildcards_folder}")
        logger.debug(f"Current working directory: {os.getcwd()}")
        logger.debug(f"Directory contents of wildcards folder: {os.listdir(wildcards_folder)}")
        
        def replace_wildcard(match, depth=0):
            if depth >= recursive_depth:
                logger.debug(f"Max depth reached: {depth}")
                return match.group(0)
            
            wildcard = match.group(1)
            file_path = os.path.join(wildcards_folder, f"{wildcard}.txt")
            logger.debug(f"Looking for file: {file_path} (depth: {depth})")
            logger.debug(f"File exists: {os.path.exists(file_path)}")
            
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = [line.strip() for line in f if line.strip()]
                    if lines:
                        choice = random.choice(lines)
                        logger.debug(f"Replaced {wildcard} with: {choice} (depth: {depth})")
                        
                        if wildcard_symbol in choice:
                            logger.debug(f"Found nested wildcard in: {choice}")
                            processed_choice = re.sub(pattern, lambda m: replace_wildcard(m, depth + 1), choice)
                            logger.debug(f"After recursive processing: {processed_choice} (depth: {depth})")
                            return processed_choice
                        else:
                            return choice
                    else:
                        logger.warning(f"File {file_path} is empty")
                        return match.group(0)
                except Exception as e:
                    logger.error(f"Error reading file {file_path}: {str(e)}")
                    return match.group(0)
            else:
                logger.warning(f"File not found: {file_path}")
                return match.group(0)

        escaped_symbol = re.escape(wildcard_symbol)
        pattern = f"{escaped_symbol}([a-zA-Z0-9_]+)"
        

        
        processed_prompt = prompt
        for i in range(recursive_depth):
            new_prompt = re.sub(pattern, lambda m: replace_wildcard(m, 0), processed_prompt)
            if new_prompt == processed_prompt:
                break
            processed_prompt = new_prompt
            logger.debug(f"Iteration {i+1} result: {processed_prompt}")
        
        logger.debug(f"Final processed prompt: {processed_prompt}")
        
        return (processed_prompt,)

    @classmethod
    def IS_CHANGED(cls, prompt, seed, wildcard_symbol, recursive_depth):
        return float(seed)




#region---------------------------# Wildcards-------------


wildcards_dir1 = Path(__file__).parent.parent  / "wildcards"
os.makedirs(wildcards_dir1, exist_ok=True)
wildcards_dir2 = Path(folder_paths.base_path) / "wildcards"


full_dirs = [wildcards_dir1, wildcards_dir2]

WILDCARDS_LIST = (
    ["None"]
    + [
        "dir1 | " + str(wildcard.relative_to(wildcards_dir1))[:-4]
        for wildcard in wildcards_dir1.rglob("*.txt")
    ]
    + [
        "base_path | " + str(wildcard.relative_to(wildcards_dir2))[:-4]
        for wildcard in wildcards_dir2.rglob("*.txt")
    ]
)


class text_stack_wildcards:
    @classmethod
    def INPUT_TYPES(s):
        inputs = {
            "required": {
                "wildcards_count": (
                    "INT",
                    {"default": 1, "min": 1, "max": 50, "step": 1},
                ),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xFFFFFFFFFFFFFFFF}),
            },
            "optional": {
                "text": (
                    "STRING",
                    {
                        "default": "",
                        "multiline": True,
                    },
                ),
            },
        }

        for i in range(1, 10):
            inputs["required"][f"wildcard_name_{i}"] = (
                WILDCARDS_LIST,
                {"default": WILDCARDS_LIST[0]},
            )

        return inputs

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("text",)
    FUNCTION = "stack_Wildcards"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def stack_Wildcards(self, wildcards_count, seed, text=None, **kwargs):

        selected_wildcards = [
            kwargs[f"wildcard_name_{i}"] for i in range(1, wildcards_count + 1)
        ]
        results = []

        for full_dir in full_dirs:
            for root, dirs, files in os.walk(full_dir):
                for wildcard in selected_wildcards:
                    if wildcard == "None":
                        continue
                    else:
                        if wildcard.startswith("dir1 | "):
                            wildcard_filename = wildcard[len("dir1 | ") :]
                            target_dir = wildcards_dir1
                        if wildcard.startswith("base_path | "):
                            wildcard_filename = wildcard[len("base_path | ") :]
                            target_dir = wildcards_dir2
                        if target_dir:
                            wildcard_file = (
                                Path(target_dir) / f"{wildcard_filename}.txt"
                            )
                            if wildcard_file.is_file():
                                with open(wildcard_file, "r", encoding="utf-8") as f:
                                    lines = f.readlines()
                                    if lines:
                                        selected_line_index = seed - 1
                                        selected_line_index %= len(lines)
                                        selected_line = lines[
                                            selected_line_index
                                        ].strip()
                                        results.append(selected_line)
                            else:
                                print(f"Wildcard File not found: {wildcard_file}")

                joined_result = ", ".join(results)
                if text == "":
                    joined_result = f"{joined_result}"
                else:
                    joined_result = f"{text},{joined_result}"
                return (joined_result,)


#endregion---------------------------# Wildcards-------------


class text_mul_Join:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                f"text{i+1}": ("STRING", {"default": "", "multiline": False}) for i in range(8)
            },
            "optional": {
                "delimiter": ("STRING", {
                    "default": "\\n",
                    "multiline": False,
                    "tooltip": "Use \\n for newline, \\t for tab, \\s for space"
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("joined_text",)
    FUNCTION = "join_text"
    CATEGORY = "Apt_Preset/prompt"

    def join_text(self, delimiter, **kwargs):
        # å¤„ç†ç‰¹æ®Šè½¬ä¹‰å­—ç¬¦
        if delimiter == "\\n":
            actual_delimiter = "\n"
        elif delimiter == "\\t":
            actual_delimiter = "\t"
        elif delimiter == "\\s":
            actual_delimiter = " "
        else:
            actual_delimiter = delimiter.strip()

        # è·å–æ‰€æœ‰è¾“å…¥
        inputs = [kwargs[f"text{i+1}"] for i in range(8)]

        # å»é™¤æ¯ä¸ªè¾“å…¥çš„é¦–å°¾ç©ºç™½
        stripped_inputs = [text.strip() for text in inputs]

        # æ‰¾åˆ°æœ€åä¸€ä¸ªéç©ºç´¢å¼•
        last_non_empty_index = -1
        for i, text in enumerate(stripped_inputs):
            if text:
                last_non_empty_index = i

        # æ„å»ºç»“æœ
        result = []
        for i, text in enumerate(stripped_inputs):
            if i <= last_non_empty_index:
                result.append(text if text else "")  # ç©ºå­—æ®µä¹Ÿä¿ç•™å ä½

        # æ‹¼æ¥å¹¶è¿”å›
        joined = actual_delimiter.join(result)
        return (joined,)


class text_mul_Split:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text": ("STRING", {"multiline": True}),
                "delimiter": ("STRING", {
                    "default": "\\n",
                    "multiline": False,
                    "tooltip": "Use \\n for newline, \\t for tab, \\s for space"
                }),
            },
        }

    RETURN_TYPES = ("LIST", "STRING", "STRING", "STRING", "STRING", 
                    "STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("list_output", "item1", "item2", "item3", "item4", 
                    "item5", "item6", "item7", "item8")
    #OUTPUT_IS_LIST = (True, False, False, False, False, False, False, False, False)
    FUNCTION = "split_text"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    def split_text(self, text, delimiter):
        # å¤„ç†ç‰¹æ®Šè½¬ä¹‰å­—ç¬¦
        if delimiter == "\\n":
            actual_delimiter = "\n"
        elif delimiter == "\\t":
            actual_delimiter = "\t"
        elif delimiter == "\\s":
            actual_delimiter = " "
        else:
            actual_delimiter = delimiter.strip()

        # ä½¿ç”¨å®é™…åˆ†éš”ç¬¦è¿›è¡Œåˆ†å‰²
        parts = [part.strip() for part in text.split(actual_delimiter)]

        # ç”Ÿæˆ8ä¸ªå›ºå®šè¾“å‡ºï¼Œä¸è¶³è¡¥ç©ºå­—ç¬¦ä¸²
        output_items = parts[:8]
        while len(output_items) < 8:
            output_items.append("")


        list_out = []
        for text_item in parts:
            list_out.append(text_item)
        

        return (list_out, *output_items)


class text_list_combine :
    @classmethod
    def INPUT_TYPES(s):
        return {"required": {
                    "text_list": (any_type,),
                    "delimiter":(["newline","comma","backslash","space"],),
                            },
                }
    RETURN_TYPES = ("STRING",) 
    RETURN_NAMES = ("text",) 
    FUNCTION = "run"
    CATEGORY = "Apt_Preset/prompt/ğŸ˜ºbackup"

    INPUT_IS_LIST = True
    OUTPUT_IS_LIST = (False,)

    def run(self,text_list,delimiter):
        delimiter=delimiter[0]
        if delimiter =='newline':
            delimiter='\n'
        elif delimiter=='comma':
            delimiter=','
        elif delimiter=='backslash':
            delimiter='\\'
        elif delimiter=='space':
            delimiter=' '
        t=''
        if isinstance(text_list, list):
            t=delimiter.join(text_list)
        return (t,)










#endregion--------------------------------------


# å¸¸é‡å®šä¹‰ï¼šæ‰€æœ‰å­—å…¸é”®å€¼å‡ä½¿ç”¨ä¸­æ–‡ï¼ŒåŒæ­¥ä¼˜åŒ–æç¤ºè¯
LENS_MAP = {
    "None": "",
    "å¹¿è§’é•œå¤´": "å¹¿è§’é•œå¤´è§†è§’ï¼ˆç­‰æ•ˆç„¦è·16-35mmï¼‰ï¼Œè§†é‡å¼€é˜”å®å¤§ï¼Œæ™¯æ·±æ·±é‚ƒï¼Œè¾¹ç¼˜ç•¸å˜è‡ªç„¶ï¼Œé€‚åˆå±•ç°å…¨æ™¯åœºæ™¯æˆ–ç©ºé—´çºµæ·±æ„Ÿ",
    "è¶…å¹¿è§’é•œå¤´": "è¶…å¹¿è§’é•œå¤´è§†è§’ï¼ˆç­‰æ•ˆç„¦è·8-15mmï¼‰ï¼Œè§†é‡æåº¦å®½å¹¿ï¼Œç©ºé—´æ‹‰ä¼¸æ„Ÿå¼ºï¼Œè¿‘å¤§è¿œå°æ•ˆæœæ˜æ˜¾ï¼Œé€‚åˆç‹­å°ç©ºé—´æˆ–éœ‡æ’¼å…¨æ™¯",
    "ä¿¯è§†é•œå¤´": "é«˜ç©ºä¿¯è§†è§’åº¦æ‹æ‘„ï¼Œè‡ªä¸Šè€Œä¸‹å‚ç›´/æ–œå‘è§†è§’ï¼Œå®Œæ•´å±•ç°ä¸»ä½“æ•´ä½“å¸ƒå±€ä¸ç¯å¢ƒå…³ç³»ï¼Œå…¨å±€è§†è§’æ¸…æ™°",
    "ä»°è§†é•œå¤´": "ä½è§’åº¦ä»°è§†æ‹æ‘„ï¼Œè‡ªä¸‹è€Œä¸Šä»°æœ›è§†è§’ï¼Œçªå‡ºä¸»ä½“é«˜è€¸æ„Ÿä¸å‹è¿«æ„Ÿï¼Œå¼ºåŒ–å‚ç›´ç»´åº¦è§†è§‰å†²å‡»",
    "ç‰¹å†™é•œå¤´": "ç‰¹å†™é•œå¤´èšç„¦ä¸»ä½“å±€éƒ¨ï¼ˆå¦‚é¢éƒ¨ã€ç»†èŠ‚ï¼‰ï¼Œç»†èŠ‚æ”¾å¤§çªå‡ºï¼Œä¸»ä½“å æ®ç”»é¢80%ä»¥ä¸Šï¼ŒèƒŒæ™¯è½»å¾®è™šåŒ–ï¼Œå‡¸æ˜¾çº¹ç†ä¸è´¨æ„Ÿ",
    "å¤§ç‰¹å†™é•œå¤´": "å¤§ç‰¹å†™é•œå¤´æè‡´èšç„¦å¾®å°ç»†èŠ‚ï¼ˆå¦‚çœ¼ç›ã€çº¹ç†ï¼‰ï¼Œä¸»ä½“å æ®ç”»é¢90%ä»¥ä¸Šï¼Œç»†èŠ‚çº¤æ¯«æ¯•ç°ï¼ŒèƒŒæ™¯å®Œå…¨è™šåŒ–",
    "å¾®è·é•œå¤´": "è¶…è¿‘è·ç¦»å¾®è·æ‘„å½±ï¼ˆæ”¾å¤§å€ç‡1:1ä»¥ä¸Šï¼‰ï¼Œæè‡´æ”¾å¤§å¾®è§‚ç»†èŠ‚ï¼Œçº¹ç†æ¸…æ™°é”åˆ©ï¼Œè‰²å½©è¿˜åŸçœŸå®ï¼Œçªå‡ºæè´¨è‚Œç†ä¸å¾®å°ç»“æ„",
    "è¿‘æ™¯é•œå¤´": "è¿‘æ™¯æ‹æ‘„èšç„¦ä¸»ä½“ä¸ŠåŠèº«/æ ¸å¿ƒåŒºåŸŸï¼Œä¸»ä½“çªå‡ºé²œæ˜ï¼ŒèƒŒæ™¯é€‚åº¦è™šåŒ–ï¼ˆæµ…æ™¯æ·±ï¼‰ï¼Œå…¼é¡¾ä¸»ä½“ç»†èŠ‚ä¸ç¯å¢ƒæ°›å›´",
    "ä¸­æ™¯é•œå¤´": "ä¸­æ™¯æ‹æ‘„å±•ç°ä¸»ä½“å®Œæ•´å½¢æ€ä¸å‘¨è¾¹ç¯å¢ƒï¼Œä¸»ä½“ä¸èƒŒæ™¯æ¯”ä¾‹åè°ƒï¼Œæ—¢èƒ½çœ‹æ¸…ä¸»ä½“åŠ¨ä½œï¼Œåˆèƒ½ä½“ç°ç¯å¢ƒå…³ç³»",
    "è¿œæ™¯é•œå¤´": "è¿œæ™¯å…¨æ™¯æ‹æ‘„ï¼Œä¸»ä½“ä¸èƒŒæ™¯åè°ƒç»Ÿä¸€ï¼Œå±•ç°å®Œæ•´åœºæ™¯æ ¼å±€ï¼Œç©ºé—´å…³ç³»æ˜ç¡®ï¼Œæ°›å›´æ„Ÿå¼ºçƒˆ",
    "å…¨æ™¯é•œå¤´": "å…¨æ™¯é•œå¤´360åº¦/å®½å¹…è¦†ç›–ï¼Œåœºæ™¯å®Œæ•´æ— é—æ¼ï¼Œç©ºé—´çºµæ·±æ„Ÿä¸å¹¿åº¦å…¼å…·ï¼Œé€‚åˆå®å¤§åœºæ™¯å±•ç°"
}

VIEW_MAP = {
    "None": "",
    "å®Œæ•´å››è§†å›¾": "å·¥ç¨‹åˆ¶å›¾æ ‡å‡†å››è§†å›¾æ­£äº¤æŠ•å½±ï¼ŒåŒ…å«å‰è§†å›¾ã€ä¾§è§†å›¾ã€åè§†å›¾ã€é¡¶è§†å›¾ï¼Œæ¯”ä¾‹ç²¾ç¡®ï¼Œçº¿æ¡æ¸…æ™°æ— ç•¸å˜ï¼Œå°ºå¯¸æ ‡æ³¨è§„èŒƒ",
    "å®Œæ•´å…­è§†å›¾": "å·¥ç¨‹åˆ¶å›¾æ ‡å‡†å…­è§†å›¾æ­£äº¤æŠ•å½±ï¼ŒåŒ…å«å‰/å/å·¦/å³/é¡¶/åº•è§†å›¾ï¼Œå…¨æ–¹ä½æ— æ­»è§’å±•ç¤ºï¼Œæœºæ¢°è®¾è®¡æ ‡å‡†è§„èŒƒ",
    "æ­£é¢è§†å›¾": "æ­£å°„æŠ•å½±æ­£é¢è§†å›¾ï¼Œä¸»ä½“æ­£é¢å®Œæ•´å¯¹ç§°å±•ç°ï¼Œä¸­å¿ƒæ„å›¾å‡è¡¡ï¼Œç»“æ„ç»†èŠ‚æ— é®æŒ¡ï¼Œè½®å»“çº¿æ¡è§„æ•´",
    "ä¾§é¢è§†å›¾": "æ­£å°„æŠ•å½±ä¾§é¢è§†å›¾ï¼Œä¸»ä½“ä¾§é¢è½®å»“æ¸…æ™°åˆ†æ˜ï¼Œæ·±åº¦ç»´åº¦ä¸åšåº¦å…³ç³»æ˜ç¡®ï¼Œä¾§è§†è§’åº¦æ— é€è§†å˜å½¢",
    "èƒŒé¢è§†å›¾": "æ­£å°„æŠ•å½±èƒŒé¢è§†å›¾ï¼Œä¸»ä½“èƒŒéƒ¨ç»“æ„å®Œæ•´å‘ˆç°ï¼Œåéƒ¨ç»†èŠ‚æ— é—æ¼ï¼Œè½®å»“ä¸æ¥å£å…³ç³»æ¸…æ™°",
    "é¡¶éƒ¨è§†å›¾": "æ­£å°„æŠ•å½±é¡¶éƒ¨è§†å›¾ï¼Œä¸»ä½“ä¿¯è§†ç»“æ„å®Œæ•´å±•ç°ï¼Œé¡¶éƒ¨å¸ƒå±€ä¸å°ºå¯¸å…³ç³»æ˜ç¡®ï¼Œæ— é®æŒ¡è§†è§’",
    "åº•éƒ¨è§†å›¾": "æ­£å°„æŠ•å½±åº•éƒ¨è§†å›¾ï¼Œä¸»ä½“ä»°è§†ç»“æ„å®Œæ•´å±•ç°ï¼Œåº•éƒ¨ç»†èŠ‚ä¸æ¥å£å…³ç³»æ¸…æ™°ï¼Œè¡¥å……é¡¶éƒ¨è§†è§’ç›²åŒº",
    "åŠä¾§é¢è§†å›¾": "45åº¦åŠä¾§æ­£äº¤è§†å›¾ï¼Œç«‹ä½“æ„Ÿä¸ç©ºé—´æ„Ÿå…¼å…·ï¼Œå‰åå±‚æ¬¡å…³ç³»æ˜ç¡®ï¼Œé€è§†è‡ªç„¶æ— ç•¸å˜ï¼Œå…¼é¡¾æ­£é¢ä¸ä¾§é¢ç»†èŠ‚",
    "30åº¦ä¾§è§†å›¾": "30åº¦ä¾§è§†æ­£äº¤è§†å›¾ï¼Œä¾§é¢ç»†èŠ‚æ›´çªå‡ºï¼Œç©ºé—´å…³ç³»æ¯”45åº¦æ›´èšç„¦ï¼Œé€‚åˆå±•ç¤ºå•ä¾§ç»“æ„"
}

MOVE_CMD = {
    "å‘å‰å¹³ç§»": "é•œå¤´ç¼“æ…¢å‘å‰å¹³ç§»ï¼Œä¸»ä½“é€æ¸æ”¾å¤§ï¼Œç”»é¢çºµæ·±æ„Ÿå¢å¼ºï¼Œå‰æ™¯ç»†èŠ‚æ¸…æ™°åŒ–",
    "å‘åå¹³ç§»": "é•œå¤´ç¼“æ…¢å‘åå¹³ç§»ï¼Œä¸»ä½“é€æ¸ç¼©å°ï¼Œåœºæ™¯èŒƒå›´æ‰©å¤§ï¼ŒèƒŒæ™¯å…ƒç´ æ›´å¤šçº³å…¥ç”»é¢",
    "å‘å·¦å¹³ç§»": "é•œå¤´å¹³ç¨³å‘å·¦å¹³ç§»ï¼Œä¸»ä½“ä½ç½®å³ç§»ï¼Œå±•ç°å·¦ä¾§ç¯å¢ƒå»¶ä¼¸ï¼Œæ„å›¾å¹³è¡¡è°ƒæ•´",
    "å‘å³å¹³ç§»": "é•œå¤´å¹³ç¨³å‘å³å¹³ç§»ï¼Œä¸»ä½“ä½ç½®å·¦ç§»ï¼Œå±•ç°å³ä¾§ç¯å¢ƒå»¶ä¼¸ï¼Œæ„å›¾é‡å¿ƒåç§»",
    "å‘ä¸Šå¹³ç§»": "é•œå¤´ç¼“æ…¢å‘ä¸Šå¹³ç§»ï¼Œè§†è§’å‡é«˜ï¼Œçªå‡ºä¸»ä½“ä¸‹éƒ¨ç»†èŠ‚ä¸ä¸Šæ–¹ç¯å¢ƒè¡”æ¥",
    "å‘ä¸‹å¹³ç§»": "é•œå¤´ç¼“æ…¢å‘ä¸‹å¹³ç§»ï¼Œè§†è§’è½»å¾®é™ä½ï¼Œçªå‡ºä¸»ä½“ä¸Šéƒ¨ç»†èŠ‚ä¸ä¸‹æ–¹ç¯å¢ƒè¡”æ¥",
    "å‘å·¦ä¸Šæ–¹å¹³ç§»": "é•œå¤´å‘å·¦ä¸Šæ–¹æ–œå‘å¹³ç§»ï¼Œè§†è§’åŒæ—¶å·¦ç§»å‡é«˜ï¼Œå±•ç°å·¦ä¸Šæ–¹åœºæ™¯å»¶ä¼¸",
    "å‘å³ä¸Šæ–¹å¹³ç§»": "é•œå¤´å‘å³ä¸Šæ–¹æ–œå‘å¹³ç§»ï¼Œè§†è§’åŒæ—¶å³ç§»å‡é«˜ï¼Œå±•ç°å³ä¸Šæ–¹åœºæ™¯å»¶ä¼¸",
    "å‘å·¦ä¸‹æ–¹å¹³ç§»": "é•œå¤´å‘å·¦ä¸‹æ–¹æ–œå‘å¹³ç§»ï¼Œè§†è§’åŒæ—¶å·¦ç§»é™ä½ï¼Œå±•ç°å·¦ä¸‹æ–¹åœºæ™¯ç»†èŠ‚",
    "å‘å³ä¸‹æ–¹å¹³ç§»": "é•œå¤´å‘å³ä¸‹æ–¹æ–œå‘å¹³ç§»ï¼Œè§†è§’åŒæ—¶å³ç§»é™ä½ï¼Œå±•ç°å³ä¸‹æ–¹åœºæ™¯ç»†èŠ‚"
}

ANGLE_CMD = {
    "æ°´å¹³å‘å·¦è½¬åŠ¨": "é•œå¤´å‘å·¦æ°´å¹³è½¬åŠ¨{}åº¦ï¼Œè§†è§’æ¨ªå‘æ‰©å±•ï¼Œå·¦ä¾§åœºæ™¯çº³å…¥ç”»é¢ï¼Œæ„å›¾å·¦ä¾§å¡«å……",
    "æ°´å¹³å‘å³è½¬åŠ¨": "é•œå¤´å‘å³æ°´å¹³è½¬åŠ¨{}åº¦ï¼Œè§†è§’æ¨ªå‘æ‰©å±•ï¼Œå³ä¾§åœºæ™¯çº³å…¥ç”»é¢ï¼Œæ„å›¾å³ä¾§å¡«å……",
    "å‘å·¦å€¾æ–œæ—‹è½¬": "é•œå¤´å‘å·¦æ—‹è½¬{}åº¦ï¼Œä¸»ä½“å‘ˆç°å·¦ä¾§å€¾æ–œè§†è§’ï¼Œå¢å¼ºåŠ¨æ€å¼ åŠ›ï¼Œè§†è§‰é‡å¿ƒå·¦ç§»",
    "å‘å³å€¾æ–œæ—‹è½¬": "é•œå¤´å‘å³æ—‹è½¬{}åº¦ï¼Œä¸»ä½“å‘ˆç°å³ä¾§å€¾æ–œè§†è§’ï¼Œå¢å¼ºåŠ¨æ€å¼ åŠ›ï¼Œè§†è§‰é‡å¿ƒå³ç§»",
    "å‘ä¸‹ä¿¯è§†": "é•œå¤´å‘ä¸‹ä¿¯è§†{}åº¦ï¼Œè§†è§’é™ä½ï¼Œçªå‡ºä¸»ä½“é¡¶éƒ¨ç»“æ„ä¸åœ°é¢/æ¡Œé¢ç¯å¢ƒçš„ä½ç½®å…³ç³»",
    "å‘ä¸Šä»°è§†": "é•œå¤´å‘ä¸Šä»°è§†{}åº¦ï¼Œè§†è§’å‡é«˜ï¼Œçªå‡ºä¸»ä½“åº•éƒ¨ç»“æ„ä¸å¤©ç©º/ä¸Šæ–¹ç¯å¢ƒçš„ä½ç½®å…³ç³»",
    "å‘å‰å€¾æ–œæ—‹è½¬": "é•œå¤´å‘å‰æ—‹è½¬{}åº¦ï¼Œè§†è§’å‰å€¾ï¼Œå¢å¼ºç”»é¢å‹è¿«æ„Ÿï¼Œä¸»ä½“è¿‘å¤§è¿œå°æ•ˆæœå¼ºåŒ–",
    "å‘åå€¾æ–œæ—‹è½¬": "é•œå¤´å‘åæ—‹è½¬{}åº¦ï¼Œè§†è§’åä»°ï¼Œå±•ç°ä¸»ä½“ä¸Šéƒ¨ä¸å¤©ç©º/ä¸Šæ–¹ç¯å¢ƒï¼Œç”»é¢å¼€é˜”åº¦æå‡",
    "é¡ºæ—¶é’ˆæ—‹è½¬": "é•œå¤´é¡ºæ—¶é’ˆæ—‹è½¬{}åº¦ï¼Œç”»é¢å‘ˆç°æ—‹è½¬åŠ¨æ€æ•ˆæœï¼Œå¢å¼ºåŠ¨æ„Ÿä¸è§†è§‰å†²å‡»",
    "é€†æ—¶é’ˆæ—‹è½¬": "é•œå¤´é€†æ—¶é’ˆæ—‹è½¬{}åº¦ï¼Œç”»é¢å‘ˆç°åå‘æ—‹è½¬åŠ¨æ€æ•ˆæœï¼Œè¥é€ ç‹¬ç‰¹è§†è§‰ä½“éªŒ"
}

class text_Qwen_camera:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {

                "é•œå¤´å¹³ç§»æ–¹å‘": (
                    [
                        "None", 
                        "å‘å‰å¹³ç§»", "å‘åå¹³ç§»", 
                        "å‘å·¦å¹³ç§»", "å‘å³å¹³ç§»", 
                        "å‘ä¸Šå¹³ç§»", "å‘ä¸‹å¹³ç§»",
                        "å‘å·¦ä¸Šæ–¹å¹³ç§»", "å‘å³ä¸Šæ–¹å¹³ç§»",
                        "å‘å·¦ä¸‹æ–¹å¹³ç§»", "å‘å³ä¸‹æ–¹å¹³ç§»"
                    ],
                    {"default": "None", "label": "é•œå¤´å¹³ç§»ï¼ˆNone=ä¸å¯ç”¨ï¼‰"}
                ),
                
                "è°ƒæ•´è§’åº¦": (
                    [
                        "None",
                        "æ°´å¹³å‘å·¦è½¬åŠ¨", "æ°´å¹³å‘å³è½¬åŠ¨",
                        "å‘å·¦å€¾æ–œæ—‹è½¬", "å‘å³å€¾æ–œæ—‹è½¬",
                        "å‘ä¸‹ä¿¯è§†", "å‘ä¸Šä»°è§†",
                        "å‘å‰å€¾æ–œæ—‹è½¬", "å‘åå€¾æ–œæ—‹è½¬",
                        "é¡ºæ—¶é’ˆæ—‹è½¬", "é€†æ—¶é’ˆæ—‹è½¬"
                    ],
                    {"default": "None", "label": "è§’åº¦è°ƒæ•´ç±»å‹ï¼ˆNone=ä¸å¯ç”¨ï¼‰"}
                ),
                "è§’åº¦æ•°å€¼": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 180, 
                    "step": 5, 
                    "display": "slider",
                }),
                
                "é•œå¤´ç±»å‹": ([
                    "None", 
                    "å¹¿è§’é•œå¤´", "è¶…å¹¿è§’é•œå¤´",
                    "ä¿¯è§†é•œå¤´", "ä»°è§†é•œå¤´",
                    "ç‰¹å†™é•œå¤´", "å¤§ç‰¹å†™é•œå¤´",
                    "å¾®è·é•œå¤´",
                    "è¿‘æ™¯é•œå¤´", "ä¸­æ™¯é•œå¤´", "è¿œæ™¯é•œå¤´", "å…¨æ™¯é•œå¤´"
                ], {"default": "None", "label": "ä¸“ä¸šé•œå¤´é€‰æ‹©ï¼ˆNone=ä¸å¯ç”¨ï¼‰"}),
                
                "è§†å›¾ç±»å‹": ([
                    "None", 
                    "å®Œæ•´å››è§†å›¾", "å®Œæ•´å…­è§†å›¾",
                    "æ­£é¢è§†å›¾", "ä¾§é¢è§†å›¾", "èƒŒé¢è§†å›¾",
                    "é¡¶éƒ¨è§†å›¾", "åº•éƒ¨è§†å›¾",
                    "åŠä¾§é¢è§†å›¾ï¼ˆ45åº¦ï¼‰", "30åº¦ä¾§è§†å›¾"
                ], {"default": "None", "label": "æ­£äº¤è§†å›¾é€‰æ‹©ï¼ˆNone=ä¸å¯ç”¨ï¼‰"}),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("æç¤ºè¯",)
    FUNCTION = "generate_prompt"
    CATEGORY = "Apt_Preset/prompt"

    def generate_prompt(self, é•œå¤´å¹³ç§»æ–¹å‘, è°ƒæ•´è§’åº¦, è§’åº¦æ•°å€¼, 
                       é•œå¤´ç±»å‹, è§†å›¾ç±»å‹):
        prompt_parts = []
        
        # å¤„ç†é•œå¤´å¹³ç§»ï¼šç›´æ¥ç”¨ä¸‹æ‹‰é€‰é¡¹ä½œä¸ºMOVE_CMDçš„é”®ï¼ˆæ— éœ€é¢å¤–æ˜ å°„ï¼‰
        if é•œå¤´å¹³ç§»æ–¹å‘ != "None":
            prompt_parts.append(MOVE_CMD.get(é•œå¤´å¹³ç§»æ–¹å‘, ""))
        
        # å¤„ç†è§’åº¦è°ƒæ•´ï¼šç›´æ¥ç”¨ä¸‹æ‹‰é€‰é¡¹ä½œä¸ºANGLE_CMDçš„é”®
        if è°ƒæ•´è§’åº¦ != "None" and è§’åº¦æ•°å€¼ > 0:
            prompt_parts.append(ANGLE_CMD.get(è°ƒæ•´è§’åº¦, "").format(è§’åº¦æ•°å€¼))
        
        # å¤„ç†ä¸“ä¸šé•œå¤´
        if é•œå¤´ç±»å‹ != "None":
            prompt_parts.append(LENS_MAP.get(é•œå¤´ç±»å‹, ""))
        
        # å¤„ç†æ­£äº¤è§†å›¾
        view_key = è§†å›¾ç±»å‹.replace("ï¼ˆ45åº¦ï¼‰", "").replace("30åº¦", "30åº¦")
        if è§†å›¾ç±»å‹ != "None":
            prompt_parts.append(VIEW_MAP.get(view_key, ""))
        
        # è¿‡æ»¤ç©ºå€¼å¹¶ä¼˜åŒ–æç¤ºè¯æµç•…åº¦
        valid_parts = list(filter(None, prompt_parts))
        if valid_parts:
            if len(valid_parts) == 1:
                final_prompt = valid_parts[0] + "ï¼Œç”»é¢æ„å›¾åè°ƒï¼Œè§†è§‰æ•ˆæœè‡ªç„¶"
            elif len(valid_parts) == 2:
                final_prompt = f"{valid_parts[0]}ï¼ŒåŒæ—¶{valid_parts[1]}ï¼Œæ•´ä½“ç”»é¢ç»Ÿä¸€å’Œè°"
            else:
                final_prompt = "ï¼Œ".join(valid_parts[:-1]) + f"ï¼Œå¹¶{valid_parts[-1]}ï¼Œç”»é¢å±‚æ¬¡ä¸°å¯Œä¸”åè°ƒ"
            final_prompt += "ï¼Œå…‰å½±è¿‡æ¸¡è‡ªç„¶ï¼Œç»†èŠ‚æ¸…æ™°å¯è¾¨"
        else:
            final_prompt = "æ ‡å‡†é•œå¤´è§†è§’ï¼ˆç­‰æ•ˆç„¦è·50mmï¼‰ï¼Œè§†è§’è‡ªç„¶æ— ç•¸å˜ï¼Œä¸»ä½“å±…ä¸­æ„å›¾ï¼Œæ™¯æ·±é€‚ä¸­ï¼Œç»†èŠ‚ä¸ç¯å¢ƒå…¼é¡¾ï¼Œå…‰å½±åè°ƒ"
        
        return (final_prompt + "ã€‚",)










